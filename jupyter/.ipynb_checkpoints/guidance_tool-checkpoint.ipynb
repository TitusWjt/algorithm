{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3afe67b5",
   "metadata": {},
   "source": [
    "LLM 在需要时调用外部工具。工具的使用可以通过多种方式实现，因为有多种可能的方式来设计提示，然后产生可以解析的输出，以触发外部工具调用。您可以自己创建和解析所有这些语法，但 Guidance 也为此提供了特殊的支持命令，这些命令既符合 LLM 的实际执行方式，也符合 OpenAI 等流行的 API。使用这种语法还有助于确保您的提示与 LLM 为工具使用而进行的微调保持一致（假设 Guidance 中相应的 LLM 对象内置了支持）。调用检测： 可以手动检测 LLM 对函数的调用，方法是将 gen 命令的 stop 或 stop_regex 参数设置为表示 LLM 正在进行函数调用的值。但更简洁的方法是使用 function_call=\"auto\" 参数。这个参数将直接传递给 LLM 对象，以便它可以设置适当的 stop_regex 参数或 API 参数（要改变这种工作方式，可以覆盖 function_call_stop 或 function_call_stop_regex 变量）。此外，还有一个 extract_function_call 变量，可以从 gen 调用返回的文本中提取可调用对象。您也可以将返回的文本视为函数，而不是手动调用，Guidance 将在后台使用 extract_function_call 命令，因此调用字符串将导致调用嵌入该字符串的工具调用。这样就可以像处理 LLM 的其他输出一样，轻松处理工具调用输出。\n",
    "\n",
    "总之，有四个特殊变量和一个 gen 参数用于在 Guidance 中使用工具。所有这些变量的默认实现都是由 LLM 对象定义的，但你可以覆盖它们来改变工具使用的工作方式：\n",
    "\n",
    "tool_def： 一个用于定义 LLM 可以使用的工具的指导程序，它会寻找一个 functions 变量，该变量包含 OpenAI 字典式函数定义语法中的函数定义。\n",
    "function_call： gen 命令的这个参数直接传递给 LLM 对象，告诉它是否应该生成函数调用。\n",
    "extract_function_call： 从 LLM 返回的文本中提取可调用对象的函数。\n",
    "function_call_stop： 用于检测 LLM 是否正在进行函数调用的字符串。\n",
    "function_call_stop_regex： 用于检测 LLM 调用函数的 regex。\n",
    "下面是 OpenAI 聊天 API 的一个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用与 OpenAI 文档中相同的模拟工具，即模拟天气服务功能。\n",
    "import json\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\" Get the current weather in a given location.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    location : string\n",
    "        The city and state, e.g. San Francisco, CA\n",
    "    unit : \"celsius\" or \"fahrenheit\"\n",
    "    \"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"71\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d436d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "\n",
    "# define the chat model we want to use (must be a recent model supporting function calls)\n",
    "guidance.llm = guidance.llms.OpenAI(\"gpt-3.5-turbo-0613\", caching=False)\n",
    "\n",
    "# define a guidance program that uses tools\n",
    "program = guidance(\"\"\"\n",
    "{{~#system~}}\n",
    "You are a helpful assistant.\n",
    "{{>tool_def functions=functions}}\n",
    "{{~/system~}}\n",
    "\n",
    "{{~#user~}}\n",
    "Get the current weather in New York City.\n",
    "{{~/user~}}\n",
    "\n",
    "{{~#each range(10)~}}\n",
    "    {{~#assistant~}}\n",
    "    {{gen 'answer' max_tokens=50 function_call=\"auto\"}}\n",
    "    {{~/assistant~}}\n",
    "\n",
    "    {{#if not callable(answer)}}{{break}}{{/if}}\n",
    "    \n",
    "    {{~#function name=answer.__name__~}}\n",
    "    {{answer()}}\n",
    "    {{~/function~}}\n",
    "{{~/each~}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the program, passing in the function definition we want to use as JSON\n",
    "executed_program = program(functions=[\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        }\n",
    "    }\n",
    "], get_current_weather=get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f88b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "executed_program[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a reusabe component for calling functions as intermediate steps in a generation\n",
    "# (note that args[0] refers to the first positional argument passed to the program when it is included)\n",
    "chat_tool_gen = guidance(\"\"\"{{~#each range(max_calls)~}}\n",
    "    {{~#assistant~}}\n",
    "    {{gen 'func_inner' temperature=temperature max_tokens=max_tokens_per_chunk function_call=function_call~}}\n",
    "    {{~/assistant~}}\n",
    "\n",
    "    {{#if not callable(func_inner)}}{{break}}{{/if}}\n",
    "\n",
    "    {{~#function name=func_inner.__name__~}}\n",
    "    {{func_inner()}}\n",
    "    {{~/function~}}\n",
    "{{~/each~}}{{set args[0] func_inner}}\"\"\", max_calls=20, function_call=\"auto\", max_tokens_per_chunk=500, temperature=0.0)\n",
    "\n",
    "# define a guidance program that uses chat_tool_gen\n",
    "program2 = guidance(\"\"\"\n",
    "{{~#system~}}\n",
    "You are a helpful assistant.\n",
    "{{>tool_def functions=functions}}\n",
    "{{~/system~}}\n",
    "\n",
    "{{~#user~}}\n",
    "Get the current weather in New York City.\n",
    "{{~/user~}}\n",
    "\n",
    "{{>chat_tool_gen 'answer'}}\"\"\", chat_tool_gen=chat_tool_gen)\n",
    "\n",
    "# call the program\n",
    "executed_program2 = program2(functions=[\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "], get_current_weather=get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a guidance program that pauses we when a function call is made\n",
    "await_program = guidance(\"\"\"\n",
    "{{~#system~}}\n",
    "You are a helpful assistant.\n",
    "{{>tool_def functions=functions}}\n",
    "{{~/system~}}\n",
    "\n",
    "{{~#user~}}\n",
    "Get the current weather in New York City.\n",
    "{{~/user~}}\n",
    "\n",
    "{{~#each range(10)~}}\n",
    "    {{~#assistant~}}\n",
    "    {{gen 'answer' temperature=1.0 max_tokens=50 function_call=\"auto\"}}\n",
    "    {{~/assistant~}}\n",
    "\n",
    "    {{set 'function_call' extract_function_call(answer)}}\n",
    "\n",
    "    {{~#if not function_call}}{{break}}{{/if~}}\n",
    "\n",
    "    {{set 'answer' await('call_result')}}\n",
    "\n",
    "    {{~#function name=function_call.__name__~}}\n",
    "    {{answer}}\n",
    "    {{~/function~}}\n",
    "{{~/each~}}\"\"\")\n",
    "\n",
    "# call the program, passing in the function definition we want to use as JSON\n",
    "executed_await_program = await_program(functions=[\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        }\n",
    "    }\n",
    "], get_current_weather=get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the details of the function call we need to make\n",
    "executed_await_program[\"function_call\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14115cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the call\n",
    "call = executed_await_program[\"function_call\"]\n",
    "if call.__name__ == \"get_current_weather\":\n",
    "    weather = get_current_weather(**call.__kwdefaults__)\n",
    "\n",
    "executed_await_program(call_result=weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd68f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
