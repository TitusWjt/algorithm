{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e106584e-aecf-4661-8c79-892004bb485d",
   "metadata": {},
   "source": [
    "# pipeline推理demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d3f4d-ac9e-4753-8809-62861e75fdc7",
   "metadata": {},
   "source": [
    "### pipeline包有一个键值对形式存在的任务列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1232d6-fcb6-4267-961e-e4492d5fc756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-classification\n",
      "automatic-speech-recognition\n",
      "text-to-audio\n",
      "feature-extraction\n",
      "text-classification\n",
      "token-classification\n",
      "question-answering\n",
      "table-question-answering\n",
      "visual-question-answering\n",
      "document-question-answering\n",
      "fill-mask\n",
      "summarization\n",
      "translation\n",
      "text2text-generation\n",
      "text-generation\n",
      "zero-shot-classification\n",
      "zero-shot-image-classification\n",
      "zero-shot-audio-classification\n",
      "conversational\n",
      "image-classification\n",
      "image-segmentation\n",
      "image-to-text\n",
      "object-detection\n",
      "zero-shot-object-detection\n",
      "depth-estimation\n",
      "video-classification\n",
      "mask-generation\n",
      "image-to-image\n",
      "('audio-classification', {'impl': <class 'transformers.pipelines.audio_classification.AudioClassificationPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForAudioClassification'>,), 'default': {'model': {'pt': ('superb/wav2vec2-base-superb-ks', '372e048')}}, 'type': 'audio'})\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines import SUPPORTED_TASKS\n",
    "l = []\n",
    "for k, v in SUPPORTED_TASKS.items():\n",
    "    l.append((k, v))\n",
    "for i in l:\n",
    "    print(i[0])\n",
    "print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5a8c0-21f7-4b10-a6db-64dacce2bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接启动服务\n",
    "import gradio as gr\n",
    "from transformers import *\n",
    "gr.Interface.from_pipeline(pipeline('text-classification', model='/root/autodl-tmp/bert-base-uncased')).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca52b84-ce9c-4b12-b13f-93ea394f9568",
   "metadata": {},
   "source": [
    "### 根据任务列表中的主键，我们就可以直接创建用于推理的pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f2f9ddf-0d33-4cd5-ba8d-83b9c625edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#先定义一个计时函数\n",
    "import torch\n",
    "import time\n",
    "def rockon(pipe):\n",
    "    times = []\n",
    "    for i in range(100):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        pipe(\"hello\")\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    print(sum(times) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eca7fcb3-527f-42a2-98b6-071c5064f888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /root/autodl-tmp/bert-base-uncased/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/root/autodl-tmp/bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /root/autodl-tmp/bert-base-uncased/model.safetensors\n",
      "Some weights of the model checkpoint at /root/autodl-tmp/bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file /root/autodl-tmp/bert-base-uncased/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/root/autodl-tmp/bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file /root/autodl-tmp/bert-base-uncased/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/root/autodl-tmp/bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#可以直接执行下面代码用于推理\n",
    "#pipe = pipeline(\"text-classification\")\n",
    "#但如果要加载预训练模型，就必须先定义model和tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/root/autodl-tmp/bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/root/autodl-tmp/bert-base-uncased\")\n",
    "pipe_cpu = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "#下面就是一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bf5b7a4-6705-4613-9bab-1874b875913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.5095895528793335}]\n",
      "cpu\n",
      "0.014024736881256104\n"
     ]
    }
   ],
   "source": [
    "print(pipe_cpu(\"hello\"))\n",
    "print(pipe_cpu.model.device)\n",
    "rockon(pipe_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a7eb0fd-5217-4750-9265-9bb34e5caa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "0.0071436047554016115\n"
     ]
    }
   ],
   "source": [
    "pipe_gpu = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)\n",
    "print(pipe_gpu.model.device)\n",
    "rockon(pipe_gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
